{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "# must make UTS/Laptop varibales\n",
    "ws_sub = r\"Decision Tree Classification\"\n",
    "ws = r\"Data\"\n",
    "data_file = \"Social_Network_Ads.csv\"\n",
    "data_file_path = os.path.join(os.path.join(os.path.join(ws, ws_sub), \"Data\"),data_file)\n",
    "dataset = pd.read_csv(data_file_path)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset\n",
    "X = dataset.iloc[:, [2, 3]].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\c.r.c\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset into the Training Set and the Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 1/4, random_state = 42)\n",
    "## must check what random_state does\n",
    "# X_train\n",
    "# X_test\n",
    "# Y_train\n",
    "# Y_train\n",
    "\n",
    "# Feature Scaling\n",
    "# feature scaling is a must do when algorithm is based on euclidian distance\n",
    "# decission tree classifier is not based on Euclidian distance\n",
    "# we leave the scaling just for the example and not to change viasualisation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(X_train)\n",
    "x_test = sc_x.fit_transform(X_test)\n",
    "# X test and train scaled with the same scale matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the classifie|r to the training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# help(DecisionTreeClassifier)\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "# criterion / gini, entropy\n",
    "# \n",
    "classifier.fit(x_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "df = pd.DataFrame(y_pred)\n",
    "df[\"test_vals\"] = Y_test\n",
    "df.rename(columns={0: \"pred_vals\"}, inplace = True)\n",
    "# df\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# help(confusion_matrix)\n",
    "cm = confusion_matrix(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the classifie|r to the training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# help(DecisionTreeClassifier)\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "# criterion / gini, entropy\n",
    "# \n",
    "classifier.fit(x_train, Y_train)\n",
    "# overfitting\n",
    "\n",
    "# Visualising the data\n",
    "from matplotlib.colors import ListedColormap\n",
    "x_set, y_set = x_train, Y_train\n",
    "x1, x2 = np.meshgrid(np.arange(start = x_set[:, 0].min() -1, stop = x_set[:, 0].max() + 1, step = 0.01),\n",
    "                    np.arange(start = x_set[:, 1].min() -1, stop = x_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(x1, x2, classifier.predict(np.array([x1.ravel(), x2.ravel()]).T).reshape(x1.shape),\n",
    "           alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(x1.min(), x1.max())\n",
    "plt.ylim(x2.min(), x2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(x_set[y_set == j, 0], x_set[y_set == j, 1], alpha = 0.75,\n",
    "               c = ListedColormap(('gray', 'yellow'))(i), label = j)\n",
    "plt.title('Decision Tree (Training set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random forest is made of classificiation of a majority of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DecisionTreeClassifier in module sklearn.tree.tree:\n",
      "\n",
      "class DecisionTreeClassifier(BaseDecisionTree, sklearn.base.ClassifierMixin)\n",
      " |  A decision tree classifier.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <tree>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  criterion : string, optional (default=\"gini\")\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |  \n",
      " |  splitter : string, optional (default=\"best\")\n",
      " |      The strategy used to choose the split at each node. Supported\n",
      " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
      " |      the best random split.\n",
      " |  \n",
      " |  max_depth : int or None, optional (default=None)\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a percentage and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a percentage and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=None)\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |          - If int, then consider `max_features` features at each split.\n",
      " |          - If float, then `max_features` is a percentage and\n",
      " |            `int(max_features * n_features)` features are considered at each\n",
      " |            split.\n",
      " |          - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |          - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, optional (default=0.)\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float,\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.\n",
      " |         Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  class_weight : dict, list of dicts, \"balanced\" or None, default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  presort : bool, optional (default=False)\n",
      " |      Whether to presort the data to speed up the finding of best splits in\n",
      " |      fitting. For the default settings of a decision tree on large\n",
      " |      datasets, setting this to true may slow down the training process.\n",
      " |      When using either a smaller dataset or a restricted depth, this may\n",
      " |      speed up the training.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array of shape = [n_classes] or a list of such arrays\n",
      " |      The classes labels (single output problem),\n",
      " |      or a list of arrays of class labels (multi-output problem).\n",
      " |  \n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances. The higher, the more important the\n",
      " |      feature. The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance [4]_.\n",
      " |  \n",
      " |  max_features_ : int,\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (for single output problems),\n",
      " |      or a list containing the number of classes for each\n",
      " |      output (for multi-output problems).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  tree_ : Tree object\n",
      " |      The underlying Tree object.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DecisionTreeRegressor\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      " |  \n",
      " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      " |  \n",
      " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      " |         Learning\", Springer, 2009.\n",
      " |  \n",
      " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      " |         http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.model_selection import cross_val_score\n",
      " |  >>> from sklearn.tree import DecisionTreeClassifier\n",
      " |  >>> clf = DecisionTreeClassifier(random_state=0)\n",
      " |  >>> iris = load_iris()\n",
      " |  >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
      " |  ...                             # doctest: +SKIP\n",
      " |  ...\n",
      " |  array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
      " |          0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DecisionTreeClassifier\n",
      " |      BaseDecisionTree\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      " |      Build a decision tree classifier from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The target values (class labels) as integers or strings.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. Splits are also\n",
      " |          ignored if they would result in any single class carrying a\n",
      " |          negative weight in either child node.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      X_idx_sorted : array-like, shape = [n_samples, n_features], optional\n",
      " |          The indexes of the sorted training input samples. If many tree\n",
      " |          are grown on the same dataset, this allows the ordering to be\n",
      " |          cached between trees. If None, the data will be sorted here.\n",
      " |          Don't use this parameter unless you know what to do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities of the input samples X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X, check_input=True)\n",
      " |      Predict class probabilities of the input samples X.\n",
      " |      \n",
      " |      The predicted class probability is the fraction of samples of the same\n",
      " |      class in a leaf.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool\n",
      " |          Run check_array on X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  apply(self, X, check_input=True)\n",
      " |      Returns the index of the leaf that each sample is predicted as.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples,]\n",
      " |          For each datapoint x in X, return the index of the leaf x\n",
      " |          ends up in. Leaves are numbered within\n",
      " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
      " |          numbering.\n",
      " |  \n",
      " |  decision_path(self, X, check_input=True)\n",
      " |      Return the decision path in the tree\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse csr array, shape = [n_samples, n_nodes]\n",
      " |          Return a node indicator matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |  \n",
      " |  predict(self, X, check_input=True)\n",
      " |      Predict class or regression value for X.\n",
      " |      \n",
      " |      For a classification model, the predicted class for each sample in X is\n",
      " |      returned. For a regression model, the predicted value based on X is\n",
      " |      returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The predicted classes, or the predict values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances.\n",
      " |      \n",
      " |      The importance of a feature is computed as the (normalized) total\n",
      " |      reduction of the criterion brought by that feature.\n",
      " |      It is also known as the Gini importance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
